{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d0ca25-a09f-485c-9955-ed2489c14dc9",
   "metadata": {},
   "source": [
    "### GetResult.py file finally\n",
    "\n",
    "Function1:Determine CF or CB\n",
    "\n",
    "Function2:get CB result(Embedding+BERD)\n",
    "\n",
    "Function3:load CF model & return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e593af3f-c49c-4913-8ea4-6460535530db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-surprise\n",
      "  Using cached scikit_surprise-1.1.3-cp310-cp310-linux_x86_64.whl\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-surprise) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-surprise) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-surprise) (1.11.4)\n",
      "Installing collected packages: scikit-surprise\n",
      "Successfully installed scikit-surprise-1.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "988aa44a-cfff-4f7d-bf46-10f2a70eabaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0e993ea-6b83-4ffa-ade2-d1be3e4402b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_data(sql_query,user_id):\n",
    "    client = bigquery.Client(project='recipe-recommendation-2024')\n",
    "    \n",
    "    # Define query parameters\n",
    "    query_params = [\n",
    "        bigquery.ScalarQueryParameter(\"user_id\", \"INT64\", int(user_id))\n",
    "    ]\n",
    "\n",
    "    # Execute the query job\n",
    "    job_config = bigquery.QueryJobConfig(query_parameters=query_params)\n",
    "    query_job = client.query(sql_query, job_config=job_config)\n",
    "\n",
    "    # Fetch the result\n",
    "    result = query_job.result()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e518f29-156b-42d7-ab59-4e14ee6f42e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function 1\n",
    "# Return 'CF' or 'CB' based on how many recipes did this user rate before\n",
    "# input parm: user_id -> which will be send by the end application\n",
    "def determine_rcs_model(user_id):\n",
    "    # Initialize BigQuery client\n",
    "    client = bigquery.Client(project='recipe-recommendation-2024')\n",
    "\n",
    "    sql_query = \"\"\"\n",
    "    SELECT COUNT(DISTINCT recipe_id) AS num_occurrences\n",
    "    FROM `recipe-recommendation-2024.RecipeQuery.interactions`\n",
    "    WHERE user_id = @user_id\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define query parameters\n",
    "    query_params = [\n",
    "        bigquery.ScalarQueryParameter(\"user_id\", \"INT64\", int(user_id))\n",
    "    ]\n",
    "\n",
    "    # Execute the query job\n",
    "    job_config = bigquery.QueryJobConfig(query_parameters=query_params)\n",
    "    query_job = client.query(sql_query, job_config=job_config)\n",
    "\n",
    "    # Fetch the result\n",
    "    result = query_job.result()\n",
    "    num_occurrences = list(result)[0].num_occurrences\n",
    "\n",
    "    if num_occurrences > 5:\n",
    "        return 'CF'\n",
    "    else:\n",
    "        return 'CB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
<<<<<<< HEAD
   "id": "77aa5c4a-9f5b-4542-816b-7aaab916064e",
=======
   "id": "b260c9c6",
>>>>>>> 99e217ab0a00465da41b10609b62e4f993b75286
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 2\n",
    "# this part will be done by jh & th\n",
    "def get_CB_model():\n",
<<<<<<< HEAD
    "    pass"
=======
    "    return model"
>>>>>>> 99e217ab0a00465da41b10609b62e4f993b75286
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37197002-1053-48cb-b4db-b193795d976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 3\n",
    "# load the trained CF model from GCS Bucket -> the model is saved by the pipeline part\n",
    "def get_CF_model(bucket_name,blob_name):\n",
    "    \n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    \n",
    "    blob = bucket.blob(blob_name)\n",
    "    \n",
    "    pickle_file = blob.download_as_bytes()\n",
    "\n",
    "    model = pickle.loads(pickle_file)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f442b142-4e38-47e9-867d-526ed4681c39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_CF_result(model,cust_user_id):\n",
    "    # get recipes list\n",
    "    sql_query_rated_recipe = \"\"\"\n",
    "        SELECT distinct recipe_id\n",
    "        FROM `recipe-recommendation-2024.RecipeQuery.interactions`\n",
    "        WHERE user_id = @user_id\n",
    "    \"\"\"\n",
    "\n",
    "    sql_query_all_recipe = \"\"\"\n",
    "        SELECT distinct recipe_id\n",
    "        FROM `recipe-recommendation-2024.RecipeQuery.interactions`\n",
    "    \"\"\"\n",
    "    rated_recipes_id_result = query_data(sql_query_rated_recipe,cust_user_id)\n",
    "    all_recipes_id_result = query_data(sql_query_all_recipe,cust_user_id)\n",
    "\n",
    "    rated_recipes_id = []\n",
    "    for row in rated_recipes_id_result:\n",
    "        rated_recipes_id.append(row[0])\n",
    "\n",
    "    all_recipes_id = []\n",
    "    for row in all_recipes_id_result:\n",
    "        all_recipes_id.append(row[0])\n",
    "\n",
    "    unrated_recipes_list = list(set(all_recipes_id) - set(rated_recipes_id))\n",
    "\n",
    "    predictions = []\n",
    "    for recipe_id in unrated_recipes_list:\n",
    "        prediction = model.predict(cust_user_id, recipe_id)\n",
    "        predictions.append({'recipe_id': recipe_id, 'predicted_rating': prediction.est})\n",
    "\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "    # Sort recipes by predicted ratings in descending order\n",
    "    predictions_df = predictions_df.sort_values(by='predicted_rating', ascending=False)\n",
    "\n",
    "    # get the recipes name and description\n",
    "    sql_query_recipe_details = \"\"\"\n",
    "    SELECT  \n",
    "      distinct id,\n",
    "      name,\n",
    "      description\n",
    "    FROM `recipe-recommendation-2024.RecipeQuery.recipes` \n",
    "    \"\"\"\n",
    "\n",
    "    recipes_detail_result = query_data(sql_query_recipe_details,'0')\n",
    "    recipes_detail = recipes_detail_result.to_dataframe()\n",
    "\n",
    "    final_predictions_df = pd.merge(predictions_df,recipes_detail,left_on='recipe_id',right_on='id',how='left')\n",
    "\n",
    "    top5_rec = []\n",
    "    for value in final_predictions_df.head().values:\n",
    "        top5_rec.append({'id':value[0],'description':value[4],'name':value[3]})\n",
    "\n",
    "    final_result = {\"recipes\":top5_rec}\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
=======
   "execution_count": 8,
   "id": "e37a7c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part will be done by jh&th\n",
    "def process_CB_results(model,cust_user_id):\n",
    "\n",
    "    #Get all recipe_id rates by user\n",
    "    sql_query_recipe_rated=\"\"\"\n",
    "        SELECT distinct recipe_id\n",
    "        FROM `recipe-recommendation-2024.RecipeQuery.interactions`\n",
    "        WHERE user_id = @user_id\n",
    "\"\"\"\n",
    "\n",
    "    #Embed user's all review\n",
    "    sql_query_embed_rated_recipe_review = \"\"\"\n",
    "with tmp as (\n",
    "    SELECT user_id,\n",
    "           STRING_AGG(review, ' ') AS aggregated_reviews\n",
    "    FROM `brave-watch-414204.RecipeQuery.interactions` \n",
    "    WHERE user_id = @user_id\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM\n",
    "ML.GENERATE_EMBEDDING(\n",
    "  MODEL `RecipeQuery.gecko_model`,\n",
    "  (SELECT aggregated_reviews as content, user_id as title FROM tmp),\n",
    "  STRUCT(TRUE AS flatten_json_output)\n",
    ")\n",
    "\"\"\"\n",
    "    #Get all recipe_id \n",
    "    sql_query_recipe_all=\"\"\"\n",
    "        SELECT distinct recipe_id\n",
    "        FROM `recipe-recommendation-2024.RecipeQuery.interactions`\n",
    "\"\"\"\n",
    "    #embed all recipes' description\n",
    "    sql_query_embed_all_recipe_description=\"\"\"\n",
    "    \n",
    "\"\"\" \n",
    "\n",
    "    sql_query_embed_rated_recipe_review = query_data(sql_query_embed_rated_recipe_review,cust_user_id)\n",
    "    sql_query_embed_all_recipe_description = query_data(sql_query_embed_all_recipe_description,cust_user_id)\n",
    "    \n",
    "    #list all the recipe_id user rated\n",
    "    rated_recipes_id = []\n",
    "    for row in sql_query_recipe_rated:\n",
    "        rated_recipes_id.append(row[0])\n",
    "\n",
    "    #list all the recipe_id\n",
    "    all_recipes_id = []\n",
    "    for row in sql_query_recipe_all:\n",
    "        all_recipes_id.append(row[0])\n",
    "    \n",
    "    #all recipes reduce those rated by users are the source we can use to predict\n",
    "    unrated_recipes_list = list(set(all_recipes_id) - set(rated_recipes_id))\n",
    "\n",
    "    predictions = []\n",
    "    for recipe_id in unrated_recipes_list:\n",
    "        prediction = model.predict(cust_user_id, recipe_id)\n",
    "        predictions.append({'recipe_id': recipe_id, 'predicted_rating': prediction.est})\n",
    "    \n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "    # Sort recipes by predicted ratings in descending order\n",
    "    predictions_df = predictions_df.sort_values(by='predicted_rating', ascending=False)\n",
    "\n",
    "    # get the recipes name and description\n",
    "    sql_query_recipe_details = \"\"\"\n",
    "    SELECT  \n",
    "      distinct id,\n",
    "      name,\n",
    "      description\n",
    "    FROM `recipe-recommendation-2024.RecipeQuery.recipes`\n",
    "    where id = \n",
    "    \"\"\"\n",
    "\n",
    "    recipes_detail_result = query_data(sql_query_recipe_details,'0')\n",
    "    recipes_detail = recipes_detail_result.to_dataframe()\n",
    "\n",
    "    final_predictions_df = pd.merge(predictions_df,recipes_detail,left_on='recipe_id',right_on='id',how='left')\n",
    "\n",
    "    top5_rec = []\n",
    "    for value in final_predictions_df.head().values:\n",
    "        top5_rec.append({'id':value[0],'description':value[4],'name':value[3]})\n",
    "\n",
    "    final_result = {\"recipes\":top5_rec}\n",
    "    return final_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
>>>>>>> 99e217ab0a00465da41b10609b62e4f993b75286
   "id": "2113f55d-0b41-4c13-9eaf-740c091de1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrated Function\n",
    "# return the Final result\n",
    "def main(cust_user_id):\n",
    "    flag = determine_rcs_model(cust_user_id)\n",
    "    if flag == 'CB':\n",
    "        model = get_CB_model()\n",
    "    elif flag == 'CF':\n",
    "        # get model\n",
<<<<<<< HEAD
    "        model = get_CF_model('recipe-recommendation-2024','model_rcs/knn_model.pkl')\n",
=======
    "        model = get_CF_model('recipe-recommendation-2024','model_rcs/svd_model.pkl')\n",
>>>>>>> 99e217ab0a00465da41b10609b62e4f993b75286
    "        final_result = process_CF_result(model,cust_user_id)\n",
    "        \n",
    "        return final_result\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown flag value: {flag}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 10,
>>>>>>> 99e217ab0a00465da41b10609b62e4f993b75286
   "id": "75c3e944-5f90-4f9d-84e7-cfbb5dee5b71",
   "metadata": {
    "tags": []
   },
<<<<<<< HEAD
   "outputs": [],
   "source": [
    "CF = main('104817')\n",
    "CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb560932-9974-4596-ba8d-db79be2e1eb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recipes': [{'id': 524236,\n",
       "   'description': '© 2014 turner broadcasting system, inc. all rights reserved.\\n\\nthis paleo-friendly chili incorporates lean ground pork, green bell peppers, onions, spinach and tomatillos. the green vegetables provide a healthy dose of vitamin c. often used in salsas, tomatillos taste like herbed lemons. charring the bell peppers, onions and tomatillos imparts a wonderful smokiness to the chili.',\n",
       "   'name': 'paleo pork chili verde'},\n",
       "  {'id': 524289,\n",
       "   'description': 'this is one of my favorite recipes to show off to friends. stuffed with leeks and bacon with an apple dijon mustard glaze. it is a very moist and tasty pork chop. i like to serve it with roasted red potatoes with fresh rosemary and sea salt, and sauteed fresh green beans.',\n",
       "   'name': 'apple glazed stuffed pork chops'},\n",
       "  {'id': 524301,\n",
       "   'description': 'another variation of a taco soup. this was made with what i had on hand. it turned out very delicious and everyone liked it. i have the taco seasoning in bulk. i also use frozen corn and not the canned',\n",
       "   'name': 'bob s taco soup with pasta'},\n",
       "  {'id': 524315,\n",
       "   'description': 'healthy way to get your fix instead of deep fried chicken',\n",
       "   'name': 'crispy chicken thighs in convection oven'},\n",
       "  {'id': 38,\n",
       "   'description': 'this is yummy and low-fat, it always turns out perfect.',\n",
       "   'name': 'low fat berry blue frozen dessert'}]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CF = main('424680')\n",
    "CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e083d0b7-bdf8-4484-a274-a6380d417d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recipes': [{'id': 523436,\n",
       "   'description': 'a classic italian-american dish that can be as simple or fancy as you want it to be.',\n",
       "   'name': 'mamas best ever spaghetti   meatballs'},\n",
       "  {'id': 523450,\n",
       "   'description': \"found this on facebook and thought i'd give it a try.\",\n",
       "   'name': 'shrimp and crab meat with rice'},\n",
       "  {'id': 523453,\n",
       "   'description': 'use more or fewer hamburger buns if you want smaller/larger patties.',\n",
       "   'name': 'joe holland s hamburgers'},\n",
       "  {'id': 523456,\n",
       "   'description': \"“try cutting the cauliflower into thin slices and pan-frying after dusting with spices,” says tom filippou, executive chef for president's choice cooking school. “you can serve this recipe as a first course garnished with a dollop of yogurt or as a main with chickpea salad and flatbread.”\",\n",
       "   'name': 'harissa cauliflower steaks'},\n",
       "  {'id': 523463,\n",
       "   'description': \"this is my version of applebee's oriental chicken salad....wonderful flavors of sweet sesame and honey. this one will be a family favorite for sure!\",\n",
       "   'name': 'oriental chicken salad with honey sesame dressing'}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CF = main('389431')\n",
=======
   "outputs": [
    {
     "ename": "Forbidden",
     "evalue": "403 POST https://bigquery.googleapis.com/bigquery/v2/projects/recipe-recommendation-2024/jobs?prettyPrint=false: Access Denied: Project recipe-recommendation-2024: User does not have bigquery.jobs.create permission in project recipe-recommendation-2024.\n\nLocation: None\nJob ID: bb9b1a91-e3d9-43a0-994b-d3937afadcd6\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m CF \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m8937\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m CF\n",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(cust_user_id)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(cust_user_id):\n\u001b[0;32m----> 4\u001b[0m     flag \u001b[38;5;241m=\u001b[39m \u001b[43mdetermine_rcs_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcust_user_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flag \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCB\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      6\u001b[0m         model \u001b[38;5;241m=\u001b[39m get_CB_model()\n",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m, in \u001b[0;36mdetermine_rcs_model\u001b[0;34m(user_id)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Execute the query job\u001b[39;00m\n\u001b[1;32m     20\u001b[0m job_config \u001b[38;5;241m=\u001b[39m bigquery\u001b[38;5;241m.\u001b[39mQueryJobConfig(query_parameters\u001b[38;5;241m=\u001b[39mquery_params)\n\u001b[0;32m---> 21\u001b[0m query_job \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Fetch the result\u001b[39;00m\n\u001b[1;32m     24\u001b[0m result \u001b[38;5;241m=\u001b[39m query_job\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/client.py:3408\u001b[0m, in \u001b[0;36mClient.query\u001b[0;34m(self, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry, api_method)\u001b[0m\n\u001b[1;32m   3397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _job_helpers\u001b[38;5;241m.\u001b[39mquery_jobs_query(\n\u001b[1;32m   3398\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3399\u001b[0m         query,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3405\u001b[0m         job_retry,\n\u001b[1;32m   3406\u001b[0m     )\n\u001b[1;32m   3407\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m api_method \u001b[38;5;241m==\u001b[39m enums\u001b[38;5;241m.\u001b[39mQueryApiMethod\u001b[38;5;241m.\u001b[39mINSERT:\n\u001b[0;32m-> 3408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_job_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_jobs_insert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3409\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_id_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_retry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3419\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3420\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unexpected value for api_method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(api_method)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_job_helpers.py:158\u001b[0m, in \u001b[0;36mquery_jobs_insert\u001b[0;34m(client, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m query_job\n\u001b[0;32m--> 158\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[43mdo_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# The future might be in a failed state now, but if it's\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# unrecoverable, we'll find out when we ask for it's result, at which\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# point, we may retry.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m job_id_given:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_job_helpers.py:135\u001b[0m, in \u001b[0;36mquery_jobs_insert.<locals>.do_query\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m query_job \u001b[38;5;241m=\u001b[39m job\u001b[38;5;241m.\u001b[39mQueryJob(job_ref, query, client\u001b[38;5;241m=\u001b[39mclient, job_config\u001b[38;5;241m=\u001b[39mjob_config)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core_exceptions\u001b[38;5;241m.\u001b[39mConflict \u001b[38;5;28;01mas\u001b[39;00m create_exc:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# The thought is if someone is providing their own job IDs and they get\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# their job ID generation wrong, this could end up returning results for\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# the wrong query. We thus only try to recover if job ID was not given.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m job_id_given:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1379\u001b[0m, in \u001b[0;36mQueryJob._begin\u001b[0;34m(self, client, retry, timeout)\u001b[0m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"API call:  begin the job via a POST request\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m \n\u001b[1;32m   1361\u001b[0m \u001b[38;5;124;03mSee\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;124;03m    ValueError: If the job has already begun.\u001b[39;00m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1379\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mQueryJob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mGoogleAPICallError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1381\u001b[0m     exc\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m=\u001b[39m _EXCEPTION_FOOTER_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1382\u001b[0m         message\u001b[38;5;241m=\u001b[39mexc\u001b[38;5;241m.\u001b[39mmessage, location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation, job_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\n\u001b[1;32m   1383\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/base.py:740\u001b[0m, in \u001b[0;36m_AsyncJob._begin\u001b[0;34m(self, client, retry, timeout)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;66;03m# jobs.insert is idempotent because we ensure that every new\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# job has an ID.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m span_attributes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: path}\n\u001b[0;32m--> 740\u001b[0m api_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBigQuery.job.begin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspan_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_api_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_properties(api_response)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/client.py:831\u001b[0m, in \u001b[0;36mClient._call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m create_span(\n\u001b[1;32m    829\u001b[0m         name\u001b[38;5;241m=\u001b[39mspan_name, attributes\u001b[38;5;241m=\u001b[39mspan_attributes, client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, job_ref\u001b[38;5;241m=\u001b[39mjob_ref\n\u001b[1;32m    830\u001b[0m     ):\n\u001b[0;32m--> 831\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry.py:349\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    346\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    348\u001b[0m )\n\u001b[0;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry.py:191\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/_http/__init__.py:494\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    482\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    483\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    484\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m     extra_api_info\u001b[38;5;241m=\u001b[39mextra_api_info,\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(response)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expect_json \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[0;31mForbidden\u001b[0m: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/recipe-recommendation-2024/jobs?prettyPrint=false: Access Denied: Project recipe-recommendation-2024: User does not have bigquery.jobs.create permission in project recipe-recommendation-2024.\n\nLocation: None\nJob ID: bb9b1a91-e3d9-43a0-994b-d3937afadcd6\n"
     ]
    }
   ],
   "source": [
    "CF = main('8937')\n",
>>>>>>> 99e217ab0a00465da41b10609b62e4f993b75286
    "CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "da0acaad-b9c7-44bd-8c35-4d33d22a305c",
=======
   "id": "1628618c-8d04-4a29-b694-6497e33c969c",
>>>>>>> 99e217ab0a00465da41b10609b62e4f993b75286
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
